{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer for neuron machine translation\n",
    "Ref: https://andrewpeng.dev/transformer-pytorch/  \n",
    "Ref: https://spaces.ac.cn/archives/6933  \n",
    "Ref: https://github.com/graykode/nlp-tutorial  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T10:26:30.051243Z",
     "start_time": "2020-03-04T10:26:28.758001Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import BucketIterator, Field\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "from torchsummaryX import summary\n",
    "\n",
    "import model\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T10:26:36.108106Z",
     "start_time": "2020-03-04T10:26:30.054449Z"
    }
   },
   "outputs": [],
   "source": [
    "BSZ = 8\n",
    "SRC = Field(tokenize='spacy',\n",
    "            tokenizer_language='de',\n",
    "            init_token='<sos>',\n",
    "            eos_token='<eos>',\n",
    "            lower=True)\n",
    "\n",
    "TRG = Field(tokenize='spacy',\n",
    "            tokenizer_language='en',\n",
    "            init_token='<sos>',\n",
    "            eos_token='<eos>',\n",
    "            lower=True)\n",
    "\n",
    "train_data, val_data, test_data = Multi30k.splits(\n",
    "    exts=('.de', '.en'), fields=(SRC, TRG))\n",
    "train_iter, val_iter, test_iter = BucketIterator.splits(\n",
    "    (train_data, val_data, test_data), batch_size=BSZ)\n",
    "\n",
    "\n",
    "SRC.build_vocab(train_data, min_freq=4)\n",
    "TRG.build_vocab(train_data, min_freq=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T10:26:36.118028Z",
     "start_time": "2020-03-04T10:26:36.110213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3625\n",
      "127\n",
      "125\n"
     ]
    }
   ],
   "source": [
    "# batch = next(iter(train_iter))\n",
    "\n",
    "# for batch_idx, batch in enumerate(train_iter):\n",
    "#     src = batch.src.transpose(0,1)[0:2]\n",
    "#     trg = batch.trg.transpose(0,1)[0:2]\n",
    "#     src = [' '.join(utils.itos(idx_seq, SRC)) for idx_seq in src]\n",
    "#     trg = [' '.join(utils.itos(idx_seq, TRG)) for idx_seq in trg]\n",
    "#     print(src)\n",
    "#     print(trg)\n",
    "    \n",
    "#     if batch_idx == 0:\n",
    "#         break\n",
    "\n",
    "print(len(train_iter))\n",
    "print(len(val_iter))\n",
    "print(len(test_iter))\n",
    "\n",
    "# print(len(TRG.vocab))\n",
    "# print(TRG.vocab.stoi[' '])\n",
    "# print(TRG.vocab.itos[0])\n",
    "\n",
    "# print(SRC.vocab.stoi['<sos>'])\n",
    "# print(TRG.vocab.stoi['<sos>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T10:26:36.238454Z",
     "start_time": "2020-03-04T10:26:36.120323Z"
    }
   },
   "outputs": [],
   "source": [
    "D_MODEL = 512\n",
    "N_HEAD = 1\n",
    "NUM_ENC_LAYERS = 1\n",
    "NUM_DEC_LAYERS = 1\n",
    "DIM_FEEDWORD = 64\n",
    "DROPOUT = 0.5\n",
    "ACTIVATION = 'relu'\n",
    "N_EPOCH = 40\n",
    "LR = 0.001\n",
    "\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "net = model.Transformer(device, len(SRC.vocab), len(TRG.vocab), D_MODEL, N_HEAD, NUM_ENC_LAYERS,\n",
    "                        NUM_ENC_LAYERS, DIM_FEEDWORD, DROPOUT, ACTIVATION).to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=SRC.vocab.stoi['<pad>'])\n",
    "path = f'bsz:{BSZ}-lr:{LR}-epoch:{N_EPOCH}-d_model:{D_MODEL}-nhead:{N_HEAD}-nlayer:{NUM_ENC_LAYERS}\\\n",
    "-nhid:{DIM_FEEDWORD}-activation:{ACTIVATION}'\n",
    "writer = SummaryWriter(os.path.join('log/', path))\n",
    "\n",
    "best_val_bleu = 0.0\n",
    "best_val_model = copy.deepcopy(net.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T10:26:36.245710Z",
     "start_time": "2020-03-04T10:26:36.241292Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(net)\n",
    "# summary(net, torch.zeros((10,1), dtype = torch.long), torch.zeros((10,1), dtype = torch.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T10:04:49.382270Z",
     "start_time": "2020-03-04T10:04:15.485321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 | val loss: 5.059 | val bleu:  0.000\n",
      "epoch: 1 | val loss: 4.887 | val bleu:  0.000\n",
      "epoch: 2 | val loss: 4.833 | val bleu:  0.000\n",
      "epoch: 3 | val loss: 4.769 | val bleu:  0.000\n",
      "epoch: 4 | val loss: 4.829 | val bleu:  0.000\n",
      "epoch: 5 | val loss: 4.791 | val bleu:  0.000\n",
      "epoch: 6 | val loss: 4.743 | val bleu:  0.000\n",
      "epoch: 7 | val loss: 4.797 | val bleu:  0.000\n",
      "epoch: 8 | val loss: 4.775 | val bleu:  0.000\n",
      "epoch: 9 | val loss: 4.765 | val bleu:  0.000\n",
      "epoch: 10 | val loss: 4.737 | val bleu:  0.000\n",
      "epoch: 11 | val loss: 4.735 | val bleu:  0.000\n",
      "epoch: 12 | val loss: 4.717 | val bleu:  0.000\n",
      "epoch: 13 | val loss: 4.725 | val bleu:  0.000\n",
      "epoch: 14 | val loss: 4.718 | val bleu:  0.000\n",
      "epoch: 15 | val loss: 4.649 | val bleu:  0.001\n",
      "epoch: 16 | val loss: 4.595 | val bleu:  0.001\n",
      "epoch: 17 | val loss: 4.591 | val bleu:  0.001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8eb7269dc609>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_bleu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'epoch: {epoch} | val loss: {val_loss:.3f} | val bleu: {val_bleu: .3f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/Machine-Translation/Transformer/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_iter, criterion, optimizer, TRG, epoch, writer, device)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mbatch_bleu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mepoch_bleu\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_bleu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/Machine-Translation/Transformer/utils.py\u001b[0m in \u001b[0;36mcount_bleu\u001b[0;34m(output, trg, TRG)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mcandidate_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRG\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx_list\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mreferences_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx_list\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbleu_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/sign/lib/python3.6/site-packages/torchtext/data/metrics.py\u001b[0m in \u001b[0;36mbleu_score\u001b[0;34m(candidate_corpus, references_corpus, max_n, weights)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidate_counter\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# TODO: no need to loop through the whole counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mtotal_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcandidate_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCH):\n",
    "    model.train(net, train_iter, criterion, optimizer, TRG, epoch, writer, device)\n",
    "    val_loss, val_bleu = model.evaluate(net, val_iter, criterion, TRG, device)\n",
    "    print(f'epoch: {epoch} | val loss: {val_loss:.3f} | val bleu: {val_bleu: .3f}')\n",
    "    \n",
    "    if val_bleu > best_val_bleu:\n",
    "        best_val_bleu = val_bleu\n",
    "        best_val_model = copy.deepcopy(net.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(best_val_model)\n",
    "test_loss, test_bleu = model.test(net, test_iter, criterion, TRG, device)\n",
    "print(f'test loss: {test_loss:.3f} | test bleu: {test_bleu: .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sign]",
   "language": "python",
   "name": "conda-env-sign-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
