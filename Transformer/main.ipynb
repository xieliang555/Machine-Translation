{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\tTransformer for neuron machine translation\n",
    "\tRef: https://andrewpeng.dev/transformer-pytorch/\n",
    "\tRef: https://spaces.ac.cn/archives/6933\n",
    "\tRef: https://github.com/graykode/nlp-tutorial\n",
    "\n",
    "'''\n",
    "\n",
    "import torch\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import BucketIterator, Field\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "from torchsummaryX import summary\n",
    "\n",
    "import model\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize='spacy',\n",
    "            tokenizer_language='de',\n",
    "            init_token='<sos>',\n",
    "            eos_token='<eos>',\n",
    "            lower=True)\n",
    "\n",
    "TRG = Field(tokenize='spacy',\n",
    "            tokenizer_language='en',\n",
    "            init_token='<sos>',\n",
    "            eos_token='<eos>',\n",
    "            lower=True)\n",
    "\n",
    "train_data, val_data, test_data = Multi30k.splits(\n",
    "    exts=('.de', '.en'), fields=(SRC, TRG))\n",
    "train_iter, val_iter, test_iter = BucketIterator.splits(\n",
    "    (train_data, val_data, test_data), batch_size=32)\n",
    "\n",
    "\n",
    "SRC.build_vocab(train_data, min_freq=4)\n",
    "TRG.build_vocab(train_data, min_freq=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(iter(train_iter))\n",
    "\n",
    "# for batch_idx, batch in enumerate(train_iter):\n",
    "#     src = batch.src.transpose(0,1)[0:2]\n",
    "#     trg = batch.trg.transpose(0,1)[0:2]\n",
    "#     src = [' '.join(utils.itos(idx_seq, SRC)) for idx_seq in src]\n",
    "#     trg = [' '.join(utils.itos(idx_seq, TRG)) for idx_seq in trg]\n",
    "#     print(src)\n",
    "#     print(trg)\n",
    "    \n",
    "#     if batch_idx == 0:\n",
    "#         break\n",
    "\n",
    "# print(len(train_iter))\n",
    "# print(len(val_iter))\n",
    "# print(len(test_iter))\n",
    "\n",
    "# print(len(TRG.vocab))\n",
    "# print(TRG.vocab.stoi[' '])\n",
    "# print(TRG.vocab.itos[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_MODEL = 512\n",
    "N_HEAD = 1\n",
    "NUM_ENC_LAYERS = 1\n",
    "NUM_DEC_LAYERS = 1\n",
    "DIM_FEEDWORD = 64\n",
    "DROPOUT = 0.5\n",
    "ACTIVATION = 'relu'\n",
    "N_EPOCH = 10\n",
    "\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "net = model.Transformer(device, len(SRC.vocab), len(TRG.vocab), D_MODEL, N_HEAD, NUM_ENC_LAYERS,\n",
    "                        NUM_ENC_LAYERS, DIM_FEEDWORD, DROPOUT, ACTIVATION).to(device)\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=SRC.vocab.stoi['<pad>'])\n",
    "writer = SummaryWriter(os.path.join(\n",
    "    'log/', time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(net)\n",
    "# summary(net, torch.zeros((10,1), dtype = torch.long), torch.zeros((10,1), dtype = torch.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 4.041 | val bleu:  0.024\n",
      "val loss: 3.908 | val bleu:  0.032\n",
      "val loss: 3.835 | val bleu:  0.016\n",
      "val loss: 3.778 | val bleu:  0.039\n",
      "val loss: 3.770 | val bleu:  0.026\n",
      "val loss: 3.753 | val bleu:  0.012\n",
      "val loss: 3.715 | val bleu:  0.036\n",
      "val loss: 3.696 | val bleu:  0.026\n",
      "val loss: 3.674 | val bleu:  0.034\n",
      "val loss: 3.682 | val bleu:  0.037\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "greedy_decoder() missing 1 required positional argument: 'trg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-08603714b470>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_val_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_bleu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'test loss: {test_loss:.3f} | test bleu: {test_bleu: .3f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/Machine-Translation/Transformer/model.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, test_iter, criterion, TRG, device)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mepoch_bleu\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mepoch_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_bleu\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: greedy_decoder() missing 1 required positional argument: 'trg'"
     ]
    }
   ],
   "source": [
    "best_val_bleu = 0.0\n",
    "best_val_model = copy.deepcopy(net.state_dict())\n",
    "for epoch in range(N_EPOCH):\n",
    "    model.train(net, train_iter, criterion, optimizer, TRG, epoch, writer, device)\n",
    "    val_loss, val_bleu = model.evaluate(net, val_iter, criterion, TRG, device)\n",
    "    print(f'val loss: {val_loss:.3f} | val bleu: {val_bleu: .3f}')\n",
    "    \n",
    "    if val_bleu > best_val_bleu:\n",
    "        best_val_bleu = val_bleu\n",
    "        best_val_model = copy.deepcopy(net.state_dict())\n",
    "\n",
    "net.load_state_dict(best_val_model)\n",
    "test_loss, test_bleu = model.test(net, test_iter, criterion, TRG, device)\n",
    "print(f'test loss: {test_loss:.3f} | test bleu: {test_bleu: .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sign]",
   "language": "python",
   "name": "conda-env-sign-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
