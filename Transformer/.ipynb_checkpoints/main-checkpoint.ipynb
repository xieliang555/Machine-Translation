{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\tTransformer for neuron machine translation\n",
    "\tRef: https://andrewpeng.dev/transformer-pytorch/\n",
    "\tRef: https://spaces.ac.cn/archives/6933\n",
    "\tRef: https://github.com/graykode/nlp-tutorial\n",
    "\n",
    "'''\n",
    "\n",
    "import torch\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import BucketIterator, Field\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "from torchsummaryX import summary\n",
    "\n",
    "import model\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize='spacy',\n",
    "            tokenizer_language='de',\n",
    "            init_token='<sos>',\n",
    "            eos_token='<eos>',\n",
    "            lower=True)\n",
    "\n",
    "TRG = Field(tokenize='spacy',\n",
    "            tokenizer_language='en',\n",
    "            init_token='<sos>',\n",
    "            eos_token='<eos>',\n",
    "            lower=True)\n",
    "\n",
    "train_data, val_data, test_data = Multi30k.splits(\n",
    "    exts=('.de', '.en'), fields=(SRC, TRG))\n",
    "train_iter, val_iter, test_iter = BucketIterator.splits(\n",
    "    (train_data, val_data, test_data), batch_size=32)\n",
    "\n",
    "\n",
    "SRC.build_vocab(train_data, min_freq=4)\n",
    "TRG.build_vocab(train_data, min_freq=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(iter(train_iter))\n",
    "\n",
    "# for batch_idx, batch in enumerate(train_iter):\n",
    "#     src = batch.src.transpose(0,1)[0:2]\n",
    "#     trg = batch.trg.transpose(0,1)[0:2]\n",
    "#     src = [' '.join(utils.itos(idx_seq, SRC)) for idx_seq in src]\n",
    "#     trg = [' '.join(utils.itos(idx_seq, TRG)) for idx_seq in trg]\n",
    "#     print(src)\n",
    "#     print(trg)\n",
    "    \n",
    "#     if batch_idx == 0:\n",
    "#         break\n",
    "\n",
    "# print(len(train_iter))\n",
    "# print(len(val_iter))\n",
    "# print(len(test_iter))\n",
    "\n",
    "# print(len(TRG.vocab))\n",
    "# print(TRG.vocab.stoi[' '])\n",
    "# print(TRG.vocab.itos[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_MODEL = 512\n",
    "N_HEAD = 1\n",
    "NUM_ENC_LAYERS = 1\n",
    "NUM_DEC_LAYERS = 1\n",
    "DIM_FEEDWORD = 64\n",
    "DROPOUT = 0.5\n",
    "ACTIVATION = 'relu'\n",
    "N_EPOCH = 10\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "net = model.Transformer(device, len(SRC.vocab), len(TRG.vocab), D_MODEL, N_HEAD, NUM_ENC_LAYERS,\n",
    "                        NUM_ENC_LAYERS, DIM_FEEDWORD, DROPOUT, ACTIVATION).to(device)\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=SRC.vocab.stoi['<pad>'])\n",
    "writer = SummaryWriter(os.path.join(\n",
    "    'log/', time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(net)\n",
    "# summary(net, torch.zeros((10,1), dtype = torch.long), torch.zeros((10,1), dtype = torch.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 | duration: 12m | end time: 19:33:05\n",
      "\ttrain loss: 5.097 | train bleu: 0.000\n",
      "\tval loss: 5.238 | val bleu: 0.000\n",
      "\n",
      "epoch: 1 | duration: 12m | end time: 19:45:27\n",
      "\ttrain loss: 4.932 | train bleu: 0.000\n",
      "\tval loss: 5.406 | val bleu: 0.000\n",
      "\n",
      "epoch: 2 | duration: 12m | end time: 19:57:55\n",
      "\ttrain loss: 4.895 | train bleu: 0.000\n",
      "\tval loss: 5.179 | val bleu: 0.000\n",
      "\n",
      "epoch: 3 | duration: 12m | end time: 20:10:27\n",
      "\ttrain loss: 4.868 | train bleu: 0.000\n",
      "\tval loss: 5.250 | val bleu: 0.000\n",
      "\n",
      "epoch: 4 | duration: 13m | end time: 20:23:57\n",
      "\ttrain loss: 4.843 | train bleu: 0.000\n",
      "\tval loss: 5.375 | val bleu: 0.000\n",
      "\n",
      "epoch: 5 | duration: 12m | end time: 20:36:41\n",
      "\ttrain loss: 4.857 | train bleu: 0.000\n",
      "\tval loss: 5.253 | val bleu: 0.000\n",
      "\n",
      "epoch: 6 | duration: 12m | end time: 20:48:56\n",
      "\ttrain loss: 4.841 | train bleu: 0.000\n",
      "\tval loss: 5.183 | val bleu: 0.000\n",
      "\n",
      "epoch: 7 | duration: 12m | end time: 21:01:22\n",
      "\ttrain loss: 4.822 | train bleu: 0.000\n",
      "\tval loss: 5.505 | val bleu: 0.000\n",
      "\n",
      "epoch: 8 | duration: 12m | end time: 21:14:19\n",
      "\ttrain loss: 4.843 | train bleu: 0.000\n",
      "\tval loss: 5.252 | val bleu: 0.000\n",
      "\n",
      "epoch: 9 | duration: 13m | end time: 21:27:36\n",
      "\ttrain loss: 4.849 | train bleu: 0.000\n",
      "\tval loss: 5.251 | val bleu: 0.000\n",
      "\n",
      "test loss: 5.284 | test bleu:  0.000\n"
     ]
    }
   ],
   "source": [
    "best_val_bleu = 0.0\n",
    "best_val_model = copy.deepcopy(net.state_dict())\n",
    "for epoch in range(N_EPOCH):\n",
    "    model.train(net, train_iter, criterion, optimizer, TRG, epoch, writer, device)\n",
    "    val_loss, val_bleu = model.evaluate(net, val_iter, criterion, TRG, device)\n",
    "    print(f'val loss: {val_loss:.3f} | val bleu: {val_bleu: .3f}')\n",
    "    \n",
    "    if val_bleu > best_val_bleu:\n",
    "        best_val_bleu = val_bleu\n",
    "        best_val_model = copy.deepcopy(net.state_dict())\n",
    "\n",
    "net.load_state_dict(best_val_model)\n",
    "test_loss, test_bleu = model.test(net, test_iter, criterion, TRG, device)\n",
    "print(f'test loss: {test_loss:.3f} | test bleu: {test_bleu: .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sign]",
   "language": "python",
   "name": "conda-env-sign-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
